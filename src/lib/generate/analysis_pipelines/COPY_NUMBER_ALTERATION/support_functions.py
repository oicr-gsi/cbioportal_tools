"""Utility functions for CAP CNA data"""

import os
import subprocess
import pandas as pd
import numpy as np


from support import Config, helper
from constants import constants # legacy constants
from utilities.constants import DATA_DIRNAME, R_SCRIPT_DIRNAME

## this is for discrete data
thresholds:list  = []

def preProcCNA(meta_config: Config.Config, study_config: Config.Config, genebed, genelist, gain, amp, htz, hmz, logger):
    oldSegData = os.path.join(study_config.config_map['output_folder'],
                            'data_{}_concat.txt'.format(constants.config2name_map[meta_config.alterationtype + ":" + meta_config.datahandler]))

    segData = os.path.join(study_config.config_map['output_folder'],
                            'data_{}.txt'.format(constants.config2name_map[meta_config.alterationtype + ":" + meta_config.datahandler]))
    
    # Rename SEG data
    os.rename(oldSegData, segData)
    
    # Set up call to preProcCNA.r script because it needs to use the bioconductor libraries which is in R and not in Python
    # TODO Instead of having to run the processes in R, change it all into python
    executable = 'Rscript'
    path2script = os.path.join(os.path.dirname(__file__), R_SCRIPT_DIRNAME, 'preProcCNA.r')
    outputPath = study_config.config_map['output_folder']
    if os.path.exists(path2script):
        args = [str(x) for x in [segData, genebed, gain, amp, htz, hmz, outputPath, genelist]]
        cmd = [executable, path2script] + args
        command_string = ', '.join(cmd)
        logger.debug('Running R script command: '+command_string)
        rc = subprocess.call(cmd)
        if rc != 0:
            msg = "Non-zero exit code %i from R script command '%s'" % (rc, command_string)
            logger.error(msg)
            raise ValueError(msg)
    else:
        raise FileNotFoundError('Cannot find R script path {}'.format(path2script))


def ProcCNA(meta_config: Config.Config, study_config: Config.Config, genebed, genelist, gain, amp, htz, hmz, oncokb_api_token, verb):
    gain = float(gain)
    amp = float(amp)
    htz = float(htz)
    hmz = float(hmz)
    
    #RETRIEVE REDUCED SEG
    outputPath = study_config.config_map['output_folder']
    
    # Reduced seg loads the segmentation file after being processed by the libaries using bioconductor,
    # this file is a temporary solution for this handler and should be replaced.
    try:
        reducedSeg = pd.read_csv(outputPath + "/data_reducedseg.txt", sep='\t')
    except FileNotFoundError:
        print('{} is the wrong file or file path'.format(outputPath + '/data_reducedseg.txt'))
    
    #REMOVE DUPLICATES FROM COLUMN 4 TO LAST COLUMN
    newColumns = reducedSeg.columns[5:]
    df_cna = reducedSeg.drop_duplicates(subset = newColumns)
    newColumns = list(newColumns)

    # Import the temporary file generated by the R script - this is a temporary solution
    os.remove(os.path.join(outputPath, "data_reducedseg.txt"))
    
    df_cna = df_cna[newColumns]
    newColumns = list(df_cna.columns)
    df_cna.rename(columns={newColumns[0]:'Hugo_Symbol'}, inplace=True)

    #ROUNDING DOES NOT GET SIG FIGS TO 4, but this was how it was done in this code previously
    df_cna[newColumns[1:]] = df_cna[newColumns[1:]].round(4) 

    # Only keep the genes in the input list genelist
    keep_genes_file = open(genelist, 'r')
    keep_genes = [line.rstrip('\n') for line in keep_genes_file.readlines()]
    keep_genes_file.close()

    # Generate log2CNA continuous file
    df_cna = df_cna[df_cna.Hugo_Symbol.isin(keep_genes)]
    
    try:
        df_cna.to_csv(os.path.join(outputPath, 'data_{}.txt'.format(constants.config2name_map[meta_config.alterationtype + ":" + 'CONTINUOUS'])), sep='\t', index=False)
    except FileNotFoundError:
        print('{} is the wrong file or file path'.format(os.path.join(outputPath, 'data_{}.txt'.format(constants.config2name_map[meta_config.alterationtype + ":" + 'CONTINUOUS']))))

    print("Thresholding CNAs")
    df_cna_thresh = df_cna

    thresholdColumns = newColumns
    df_cna_thresh[thresholdColumns[1:]] = df_cna_thresh[thresholdColumns[1:]].astype(float)
 
    #Thresholding data using the threholds from meta_config.config_map which are set in the headers of the configuration file segmentation.txt
    print("Thresholding data")
    for i in thresholdColumns:
        if i == thresholdColumns[0]:
            continue
        ampfilter = (df_cna_thresh[i] > amp)
        hmzfilter = (df_cna_thresh[i] < hmz)
        gainfilter = (df_cna_thresh[i] > gain) & (df_cna_thresh[i] <= amp)
        htzfilter = (df_cna_thresh[i] < htz) & (df_cna_thresh[i] >= hmz)
        newVals = [2, -2, 1, -1]
        
        df_cna_thresh[i] = np.select([ampfilter, hmzfilter, gainfilter, htzfilter], newVals, default=0)

    #Generate discrete CNA data
    df_cna_thresh = df_cna_thresh[df_cna_thresh.Hugo_Symbol.isin(keep_genes)]
    try:
        df_cna_thresh.to_csv(os.path.join(outputPath, 'data_{}.txt'.format(constants.config2name_map[meta_config.alterationtype + ":" + 'DISCRETE'])), sep='\t', index=False)
    except FileNotFoundError:
        print('{} is the wrong file or file path'.format(os.path.join(outputPath, 'data_{}.txt'.format(constants.config2name_map[meta_config.alterationtype + ":" + 'DISCRETE']))))

    # Truncate data_CNA
    trunc_filter = [0]
    df_cna_thresh = df_cna_thresh[~df_cna_thresh[newColumns[1:]].isin(trunc_filter).all(axis=1)]
    os.makedirs(os.path.join(outputPath, 'supplementary_data'), exist_ok=True)
    data_path = os.path.join(outputPath, 'supplementary_data', 'data_{}_short.txt'.format(constants.config2name_map[meta_config.alterationtype + ":" + 'DISCRETE']))
    try:
        df_cna_thresh.to_csv(data_path, sep='\t', index=False)
    except FileNotFoundError:
        print('{} is the wrong file or file path'.format(data_path))

    # if TYPEC is 'mixed'
    if (meta_config.config_map['typec'] != "mixed"):
        # Create oncokb_clinical_info
        f_out = os.path.join(outputPath, 'supplementary_data', 'oncokb_clinical_info.txt')
        f = open(f_out, 'w')
        f.write('SAMPLE_ID\tONCOTREE_CODE')
        f.flush()
        f.close()
    else:
        # call CNA annotator
        f_out = os.path.join(outputPath, 'supplementary_data', 'data_{}_oncoKB.txt'.format(constants.config2name_map[meta_config.alterationtype + ":" + 'DISCRETE']))
        if os.path.exists(data_path):
            cmd = "CnaAnnotator.py -i {} -o {} -b {}".format(data_path, f_out, oncokb_api_token)
            subprocess.call(cmd, shell=True)
        else:
            print('{} wrong file or file path'.format(data_path))

def fix_chrom(exports_config: Config.Config, study_config: Config.Config, verb):
    # Append 'chr' to chromosome if needed
    # Gather ingredients
    calls = []
    output_folder = study_config.config_map['output_folder']
    input_folder = exports_config.config_map['input_folder']
    export_data = exports_config.data_frame

    seg_temp = helper.get_temp_folder(output_folder, 'seg')

    # Cook
    for i in range(len(export_data)):
        helper.working_on(verb, 'Removing chr from {}'.format(export_data['FILE_NAME'][i]))
        input_file = os.path.join(input_folder, export_data['FILE_NAME'][i])
        output_file = os.path.join(seg_temp, export_data['FILE_NAME'][i])
        output_temp = output_file + '.temp'
        cmd = 'awk \'NR>1 {{sub(/\\tchr/,"\\t")}} 1\' {} > {}; mv {} {}'.format(input_file, output_temp, output_temp, output_file)
        calls.append(subprocess.Popen(command, shell=True))

    exports_config.config_map['input_folder'] = seg_temp
    # Wait until Baked
    exit_codes = [p.wait() for p in calls]
    # Clean up
    if any(exit_codes):
        raise ValueError('ERROR:: Something went wrong when parsing Segmented format file? Please resolve the issue')
    if verb:
        print(exit_codes)


def fix_seg_id(exports_config: Config.Config, study_config: Config.Config, verb):
    # Replace whatever ID is there with the Sample_ID
    # Gather ingredients
    calls = []
    output_folder = study_config.config_map['output_folder']
    input_folder = exports_config.config_map['input_folder']
    export_data = exports_config.data_frame

    seg_temp = helper.get_temp_folder(output_folder, 'seg')

    for i in range(len(export_data)):
        helper.working_on(verb, 'Resolving Sample_ID {}'.format(export_data['FILE_NAME'][i]))

        input_file = os.path.join(input_folder, export_data['FILE_NAME'][i])
        output_file = os.path.join(seg_temp, export_data['FILE_NAME'][i])
        sample_id = export_data['SAMPLE_ID'][i]

        output_temp = output_file + '.temp'

        cmd = 'head -n 1 "{}" > {}; '.format(input_file, output_temp) +\
              'cat  {} |'.format(input_file) +\
              'awk -F"\\t" \'NR>1 {{ OFS="\\t"; '+\
              'print "{}", $2, $3, $4, $5, $6}}\' >> {}; '.format(sample_id, output_temp) +\
              'mv {} {}'.format(output_temp, output_file)
        calls.append(subprocess.Popen(cmd, shell=True))

    exports_config.config_map['input_folder'] = seg_temp
    exit_codes = [p.wait() for p in calls]
    if any(exit_codes):
        raise ValueError('ERROR:: Something went wrong when parsing Segmented format file? Please resolve the issue')
    if verb:
        print(exit_codes)


def fix_hmmcopy_tsv(exports_config: Config.Config, study_config: Config.Config, verb):
    # Fix the header
    # Gather ingredients
    calls = []
    output_folder = study_config.config_map['output_folder']
    input_folder = exports_config.config_map['input_folder']
    export_data = exports_config.data_frame
    #input(export_data)
    seg_temp = helper.get_temp_folder(output_folder, 'seg')

    bed_filter = subprocess.check_output(['awk "NR>1" {} | '
                                          'awk -F"\\t" \'{{print $1}}\' | '
                                          'uniq'.format(exports_config.config_map['bed_file'])],
                                         shell=True).decode("utf-8")
    #input(bed_filter)
    bed_filter = bed_filter.strip().split('\n')
    bed_filter = bed_filter + ['chr' + a for a in bed_filter]
    bed_filter = ['\\t' + a + '\\t' for a in bed_filter]
    #input(bed_filter)

    header = 'ID\\tchrom\\tloc.start\\tloc.end\\tnum.mark\\tseg.mean'
    for i in range(len(export_data)):
        input_file = os.path.join(input_folder, export_data['FILE_NAME'][i])
        output_file = os.path.join(seg_temp, export_data['FILE_NAME'][i])
        sample_id = export_data['SAMPLE_ID'][i]

        helper.working_on(verb, 'Refactoring cols: {}'.format(export_data['FILE_NAME'][i]))
        output_temp = output_file + '.temp'
        # Get all the genes in the .bed; save each line with a matching gene; rename the Sample_ID
        # TODO get rid of this ugly & fragile bash script, rewrite using Python
        # See comments by LEH in earlier commit
        columns = '1' # placeholder for num.mark columns
        cmd = 'echo "{}" > {}; '.format(header, output_temp) +\
              'cat  {} | '.format(input_file) +\
              'awk \'BEGIN{{split("{}",t); '.format('|'.join(bed_filter))+\
              'for (i in t) vals[t[i]]}} ($2 in vals)\' | '+\
              'awk -F"\\t" \'{{ OFS="\\t"; '+\
              'print "{}", $2, $3, $4, {}, $5}}\' >> {}; '.format(sample_id, output_temp, columns) +\
              'mv {} {}'.format(output_temp, output_file)
        calls.append(subprocess.Popen(cmd, shell=True))
        exports_config.config_map['input_folder'] = seg_temp
        exit_codes = [p.wait() for p in calls]
    if any(exit_codes):
        raise ValueError('ERROR:: Something went wrong when parsing HMMCopy format file? Please resolve the issue')
    if verb:
        print(exit_codes)


def fix_hmmcopy_max_chrom(exports_config: Config.Config, study_config: Config.Config, janus_path, verb):
    # TODO janus_path argument is not used, can remove; replace verb with logger
    # Replace chromosome numbers that exceed chromosome length with chromosome length
    # Write num.mark as a n arbitrary operation
    calls = []
    output_folder = study_config.config_map['output_folder']
    input_folder = exports_config.config_map['input_folder']
    export_data = exports_config.data_frame
    seg_temp = helper.get_temp_folder(output_folder, 'seg')

    for i in range(len(export_data)):

        input_file = os.path.join(input_folder, export_data['FILE_NAME'][i])
        output_file = os.path.join(seg_temp, export_data['FILE_NAME'][i])
        dictionary = os.path.join(os.path.dirname(__file__), DATA_DIRNAME, 'hmmcopy_chrom_positions.txt')
        output_temp = output_file + '.temp'
        cmd = "awk -F'\\t' 'BEGIN {{OFS = FS}} FNR==NR {{dict[$1]=$2; next}} "+\
              "FNR >= 2 {{$4=($4 in dict) ? dict[$4] : $4; "+\
              "$5=int(($4-$3)/1000)}}1' {} {} > {};".format(dictionary, input_file, output_temp)+\
              'mv {} {}'.format(output_temp, output_file)
        calls.append(subprocess.Popen(cmd, shell=True))

    exports_config.config_map['input_folder'] = seg_temp
    exit_codes = [p.wait() for p in calls]

    # Clean up
    if any(exit_codes):
        raise ValueError('ERROR:: Something went wrong when parsing HMMCopy format file? Please resolve the issue')
    if verb:
        print(exit_codes)


def get_sample_ids(exports_config: Config.Config, verb) -> pd.Series:
    data = pd.read_csv(os.path.join(exports_config.config_map['input_folder'],
                                    exports_config.data_frame['FILE_NAME'][0]),
                       sep='\t', usecols=['ID'])

    helper.working_on(verb, message='Parsing importable {} file ...'.format(exports_config.type_config))
    return data['ID'].drop_duplicates(keep='first', inplace=False)


def verify_final_seg_file(exports_config: Config.Config, verb):
    seg = open(os.path.join(exports_config.config_map['input_folder'],
                            exports_config.data_frame['FILE_NAME'][0]), 'w')

    header = seg.readline().strip().split('\t')
    minimum_header = ['ID', 'chrom', 'loc.start', 'loc.end', 'num.mark', 'seg.mean']

    helper.working_on(verb, message='Asserting minimum header is in SEG file.')
    if not all([a in header for a in minimum_header]):
        print([a if a not in header else '' for a in minimum_header])
        print('Missing headers from SEG file have been printed above, please ensure the data is not missing.')
        exit(1)


def gen_log2cna(exports_config: Config.Config, study_config: Config.Config, janus_path, verb):
    # TODO janus_path argument is not used, can remove; replace verb with logger
    helper.working_on(verb, message='Gathering files ...')
    seg_file = os.path.join(study_config.config_map['output_folder'],
                            'data_{}.txt'.format(constants.config2name_map['SEG']))
    bed_file = exports_config.config_map['bed_file']
    l_o_file = os.path.join(study_config.config_map['output_folder'],
                            'data_{}.txt'.format(constants.config2name_map[exports_config.type_config]))

    helper.working_on(verb, message='Generating log2CNA...')

    executable = 'Rscript'
    r_script_path = os.path.join(os.dirname(__file__), R_SCRIPT_DIRNAME, 'seg2gene.r')
    if os.path.exists(r_script_path):
        cmd = ', '.join([executable, r_script_path, seg_file, bed_file, l_o_file])
        logger.debug('Running R script command: '+cmd)
        rc = subprocess.call(cmd)
        if rc != 0:
            msg = "Non-zero exit code %i from R script command '%s'" % (rc, cmd)
            raise ValueError(msg)
    else:
        raise FileNotFoundError('Cannot find R script path {}'.format(r_script_path))


def verify_final_continuous_file(exports_config: Config.Config, verb):
    data = open(os.path.join(exports_config.config_map['input_folder'],
                             exports_config.data_frame['FILE_NAME'][0]), 'w')

    t_config = exports_config.type_config
    header = data.readline().strip().split('\t')
    minimum_header = ['Entrez_Gene_Id', 'Hugo_Symbol']

    helper.working_on(verb, message='Asserting minimum header is in {} file.'.format(t_config))
    if not any([a in header for a in minimum_header]):
        print([a if a not in header else '' for a in minimum_header])
        print('Missing header(s) from {} file have been printed above, ensure data isn\'t missing.'.format(t_config))
        exit(1)





def collapse(num):
    [hmzd, htzd, gain, ampl] = thresholds

    if num > ampl:
        return +2

    elif num > gain:
        return +1

    elif num > htzd:
        return +0

    elif num > hmzd:
        return -1

    else:
        return -2


def gen_dcna(exports_config: Config.Config, study_config: Config.Config, verb):

    # This is dCNA
    # Requires cCNA to be generated already
    helper.working_on(verb, message='Gathering files ...')
    l_o_file = os.path.join(study_config.config_map['output_folder'],
                            'data_{}.txt'.format(constants.config2name_map['CONTINUOUS_COPY_NUMBER']))
    c_o_file = os.path.join(study_config.config_map['output_folder'],
                            'data_{}.txt'.format(constants.config2name_map[exports_config.type_config]))
    global thresholds
    thresholds = [float(x) for x in exports_config.config_map['thresholds'].split(',')]
    if os.path.exists(l_o_file):
        helper.working_on(verb, message='Generating dCNA (CNA)...')
        data = pd.read_csv(l_o_file, sep='\t')
        cols = data.columns.values.tolist()[1:]

        # This code here had an astonishing 5500x improvement compared to traversal over it as a 2D array, and yes 5500x
        for c in cols:
            data[c] = data[c].apply(lambda x: collapse(x))

        data.to_csv(c_o_file, sep='\t', index=None)
    else:
        print('ERROR:: Cannot generate dCNA file because log2CNA file does not exist ...')
        print('ERROR:: Either remove the DISCRETE data config file, or add a CONTINUOUS data config file ')
        helper.stars()
        helper.stars()
        exit(1)


def verify_final_discrete_file(exports_config: Config.Config, verb):
    data = open(os.path.join(exports_config.config_map['input_folder'],
                             exports_config.data_frame['FILE_NAME'][0]), 'w')

    t_config = exports_config.type_config
    header = data.readline().strip().split('\t')
    minimum_header = ['Entrez_Gene_Id', 'Hugo_Symbol']

    helper.working_on(verb, message='Asserting minimum header is in {} file.'.format(t_config))
    if not any([a in header for a in minimum_header]):
        print([a if a not in header else '' for a in minimum_header])
        print('Missing header(s) from {} file have been printed above, ensure data isn\'t missing.'.format(t_config))
        exit(1)
